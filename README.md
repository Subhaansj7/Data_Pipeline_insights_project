# Data_Pipeline_insights_project
Formula 1 Data Pipeline and Insights Project

Developed a comprehensive data pipeline leveraging the Ergast API and Azure cloud platform to analyze Formula 1 data. Utilized Azure Data Lake Storage (ADLS) for raw and processed data layers and Databricks for computing and data transformations. Implemented data ingestion, transformations, and analysis using PySpark, Spark SQL, and Python. Managed workflows through Azure Data Factory. Key achievements include deriving insights on dominant drivers and teams, and visualizing results using Databricks dashboards.

Technologies Used:

-Azure Data Lake Storage (ADLS)
-Databricks
-PySpark
-Spark SQL
-Python
-Azure Data Factory

Key Responsibilities:

-Ingested data from the Ergast API into Databricks.
-Managed data workflows and transformations.
-Created tables, views, and applied filters, joins, and aggregations.
-Analyzed data to identify dominant drivers and teams.
-Created and visualized insights using Databricks dashboards.
-Managed all pipeline steps from data ingestion to visualization using Azure Data Factory.
